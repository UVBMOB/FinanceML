{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings            \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_none(data, col_name):\n",
    "    data.drop(index = data[data[col_name]=='NONE'].index, inplace = True)\n",
    "    return data\n",
    "# data_result.drop(index = data_result[data_result['30_signal']=='NONE'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    # verinin okunması\n",
    "    # soru işaretleri olan satırlar veriden silindi.\n",
    "    data = data.replace(\"?\", np.nan)\n",
    "    data = data.dropna()\n",
    "    # verinin feature larının ayrılması\n",
    "    df = data.iloc[:,5:430]\n",
    "    df_first = data.iloc[:,1:5]\n",
    "    df_result = data.iloc[:,430:-1]\n",
    "    df_result = df_result.astype('category')\n",
    "    return df, df_first, df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_ortalama():\n",
    "    y_max1 = df_result.mode(axis=1)\n",
    "    y = pd.DataFrame(y_max1[0])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametrik fonk. tanımlaması\n",
    "# 1 : \n",
    "# 2 :\n",
    "\n",
    "def kategorikleri_dummy_yap(df):\n",
    "    cat_column_names = ['ind_7','ind_11','ind_24','ind_38','ind_54','ind_57','ind_60','ind_63','ind_66','ind_69','ind_72','ind_75',\n",
    "                    'ind_78','ind_81','ind_84','ind_87','ind_89','ind_91','ind_93','ind_95','ind_97','ind_99','ind_101',\n",
    "                    'ind_103','ind_105','ind_107','ind_109', 'ind_111', 'ind_113', 'ind_115','ind_138','ind_141','ind_144',\n",
    "                    'ind_157','ind_159','ind_161','ind_163','ind_165','ind_167','ind_169','ind_171','ind_173','ind_175',\n",
    "                    'ind_177','ind_182','ind_184','ind_187','ind_190','ind_193','ind_196','ind_199','ind_202','ind_205',\n",
    "                    'ind_208','ind_211','ind_213','ind_384','ind_386','ind_388','ind_390']\n",
    "    # categorical kolonların dummy var. oalrak değiştirdik\n",
    "    dms = pd.get_dummies(df[cat_column_names])\n",
    "    dms_none_cols = dms.filter(regex = '_NONE').columns\n",
    "    for i in dms_none_cols:\n",
    "        dms.drop(i,axis=1,inplace=True)\n",
    "    dms_red_cols = dms.filter(regex = '_RED').columns\n",
    "    for i in dms_red_cols:\n",
    "        dms.drop(i,axis=1,inplace=True)\n",
    "    #datadan categorical olan kolonları çıkarıyoruz ve type nı değiştiriyoruz\n",
    "    df_noncategoric = df.drop(cat_column_names,axis=1).astype(\"float64\")\n",
    "    df_noncategoric = pd.DataFrame(df_noncategoric)\n",
    "    df_all = pd.concat([df_noncategoric, dms], axis=1)\n",
    "    # y değerlerinin alınması\n",
    "    return df_all, df_noncategoric, dms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 - dropping correlaritions\n",
    "def corr_df(df, corr_val):\n",
    "    corr_matrix = df_noncategoric.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_high = [column for column in upper.columns if any(upper[column] > corr_val)]\n",
    "    df.drop(to_high, axis = 1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 RandomForest\n",
    "# bütün değişkenlerle yapılan random forest sonucu importance değeri verilen parametreden büyük olan değişkenleri döner\n",
    "def rand_forest(X, y, imp_value):\n",
    "    rf_model = RandomForestClassifier().fit(X, y)\n",
    "    Importance = pd.DataFrame({'Importance':rf_model.feature_importances_*100}, index = X.columns)\n",
    "    imp_values = Importance.sort_values(by = 'Importance', axis = 0, ascending = True)\n",
    "    imp_values = imp_values[imp_values['Importance']>imp_value]\n",
    "    col_names = imp_values.index   \n",
    "    return X[col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 - pca\n",
    "def pca_fon(X, threshold):\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(scale(X))\n",
    "    arr = np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)\n",
    "    num_var = sum((arr < threshold*100)) + 1 \n",
    "    print('pca sonrası değişken sayısı: ',num_var)\n",
    "    X_pcad = pd.DataFrame(X_pca[:,0:num_var], index = X.index)\n",
    "    return X_pcad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, shuffle = False)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1 - multi lojistik\n",
    "def multi_logit(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "    log = logreg.fit(X_train, y_train)\n",
    "    y_pred = log.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 - decision tree\n",
    "def dec_tree(X_train, X_test, y_train, y_test):\n",
    "    cart = DecisionTreeClassifier()\n",
    "    cart_model = cart.fit(X_train, y_train)\n",
    "    y_pred = cart_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_boost(X_train, X_test, y_train, y_test):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    print('grad_boost----------------')\n",
    "    gbm_model = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "    y_pred = gbm_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_boost(X_train, X_test, y_train, y_test):\n",
    "    from xgboost import XGBClassifier\n",
    "    print('xgb_boost----------------')\n",
    "    xgb_model = XGBClassifier().fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightGBM(X_train, X_test, y_train, y_test):\n",
    "    from lightgbm import LGBMClassifier\n",
    "    print('lightGBM----------------')\n",
    "    lgbm_model = LGBMClassifier(verbose=-1).fit(X_train,y_train)    \n",
    "    y_pred = lgbm_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catBoost(X_train, X_test, y_train, y_test):\n",
    "    from catboost import CatBoostClassifier\n",
    "    print('CatBoost----------------')\n",
    "    cat_model = CatBoostClassifier().fit(X_train, y_train)\n",
    "    y_pred = cat_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.3 - Boosting\n",
    "def boostings(X_train, X_test, y_train, y_test):\n",
    "    grad_boost(X_train, X_test, y_train, y_test)\n",
    "    xgb_boost(X_train, X_test, y_train, y_test)\n",
    "    # lightGBM(X_train, X_test, y_train, y_test)\n",
    "    # catBoost(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 - decision tree\n",
    "def dec_tree_withcv(X_train, X_test, y_train, y_test):\n",
    "    cart = DecisionTreeClassifier()\n",
    "    cart_model = cart.fit(X_train, y_train)\n",
    "    y_pred = cart_model.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    print('-------------------------------')\n",
    "    print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "    print('-------------------------------')\n",
    "    print('Classification report')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verinin okunması - df: ilk 5 kolon ve result'lar hariç kolonlar, df_first: ilk 5 kolon, df_result: sonuç kolonları\n",
    "data = pd.read_csv('EurUsd.csv')\n",
    "data = drop_none(data, '80_signal')\n",
    "df, df_first, df_result = prepare_data(data)\n",
    "y = df_result['80_signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16872, 206)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.1 den gelen veriler (non correlatedlardan gelenler)\n",
    "df_all, df_noncategoric, dms = kategorikleri_dummy_yap(df)\n",
    "df_noncorr = corr_df(df_noncategoric, 0.50)\n",
    "X1_1 = pd.concat([df_first, df_noncorr, dms], axis=1)\n",
    "X1_1.shape  #non correlatedları çıkarınca elimizde 204 kolon kaldı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16872, 268)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 den gelen veriler. \n",
    "# Notlar: \n",
    "# 1 - y için iterasyon denenebilir. y kolonu '220_signal' seçilmiştir.\n",
    "# 2- importance treshold'u 0.05 seçilmiştir, cv yapılabilir.\n",
    "X_raw = pd.concat([df_first,df_all], axis=1) \n",
    "X1_2 = rand_forest(X_raw, y, 0.05)    \n",
    "X1_2.shape #elimizde 285 kolon kaldı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca sonrası değişken sayısı:  189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((16872, 486), (16872, 189))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3 den gelen veriler.\n",
    "X_raw2 = pd.concat([df_first,df_all], axis=1) \n",
    "X1_3 = pca_fon(X_raw2, 0.99)\n",
    "X_raw2.shape, X1_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_1 için multi log\n",
      "Accuracy:  0.4685894903200316\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[ 841 1345]\n",
      " [1345 1531]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.38      0.38      0.38      2186\n",
      "        SELL       0.53      0.53      0.53      2876\n",
      "\n",
      "    accuracy                           0.47      5062\n",
      "   macro avg       0.46      0.46      0.46      5062\n",
      "weighted avg       0.47      0.47      0.47      5062\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.30)\n",
    "print('X1_1 için multi log')\n",
    "multi_logit(X_train1, X_test1, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_2 için multi log\n",
      "Accuracy:  0.46483603318846306\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[ 717 1469]\n",
      " [1240 1636]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.37      0.33      0.35      2186\n",
      "        SELL       0.53      0.57      0.55      2876\n",
      "\n",
      "    accuracy                           0.46      5062\n",
      "   macro avg       0.45      0.45      0.45      5062\n",
      "weighted avg       0.46      0.46      0.46      5062\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.30)\n",
    "print('X1_2 için multi log')\n",
    "multi_logit(X_train2, X_test2, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_3 için multi log\n",
      "Accuracy:  0.46286052943500594\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1429  757]\n",
      " [1962  914]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.42      0.65      0.51      2186\n",
      "        SELL       0.55      0.32      0.40      2876\n",
      "\n",
      "    accuracy                           0.46      5062\n",
      "   macro avg       0.48      0.49      0.46      5062\n",
      "weighted avg       0.49      0.46      0.45      5062\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.30)\n",
    "print('X1_3 için multi log')\n",
    "multi_logit(X_train3, X_test3, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_1 için dec tree\n",
      "Accuracy:  0.5517581983405768\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1488  698]\n",
      " [1571 1305]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.49      0.68      0.57      2186\n",
      "        SELL       0.65      0.45      0.53      2876\n",
      "\n",
      "    accuracy                           0.55      5062\n",
      "   macro avg       0.57      0.57      0.55      5062\n",
      "weighted avg       0.58      0.55      0.55      5062\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.30)\n",
    "print('X1_1 için dec tree')\n",
    "dec_tree(X_train1, X_test1, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_2 için dec tree\n",
      "Accuracy:  0.5539312524693797\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1110 1076]\n",
      " [1182 1694]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.48      0.51      0.50      2186\n",
      "        SELL       0.61      0.59      0.60      2876\n",
      "\n",
      "    accuracy                           0.55      5062\n",
      "   macro avg       0.55      0.55      0.55      5062\n",
      "weighted avg       0.56      0.55      0.56      5062\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.30)\n",
    "print('X1_2 için dec tree')\n",
    "dec_tree(X_train2, X_test2, y_train, y_test)\n",
    "print('*************************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_3 için dec tree\n",
      "Accuracy:  0.5005926511260371\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1083 1103]\n",
      " [1425 1451]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.43      0.50      0.46      2186\n",
      "        SELL       0.57      0.50      0.53      2876\n",
      "\n",
      "    accuracy                           0.50      5062\n",
      "   macro avg       0.50      0.50      0.50      5062\n",
      "weighted avg       0.51      0.50      0.50      5062\n",
      "\n",
      "*************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.30)\n",
    "print('X1_3 için dec tree')\n",
    "dec_tree(X_train3, X_test3, y_train, y_test)\n",
    "print('*************************************************************************************')\n",
    "\n",
    "#for i in y.columns:\n",
    "    #print(i, ' kolonu için sonuçlar:')\n",
    "    #dec_tree(X_train3, X_test3, y_train[i], y_test[i])\n",
    "    #print('*************************************************************************************')3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yol haritası\n",
    "\n",
    "1. verilerin sadeleştirilmesi \n",
    "\n",
    "    1.1 correlatedları atarak non correlated ları bul \n",
    " \n",
    "    1.2 RandomForest'dan important değişkenleri bul \n",
    " \n",
    "    1.3 pca  \n",
    " \n",
    " \n",
    "2. algoritmalar \n",
    "\n",
    "    2.1 algoritmaları fonk. olarak yaz\n",
    " \n",
    "        2.1.1 loj reg\n",
    "  \n",
    "        2.1.2 decision tree\n",
    "  \n",
    "        2.1.3 boosting\n",
    "      \n",
    "    2.2 cross validations\n",
    " \n",
    "    2.3 1'de bulduğun verilerle bütün algoritmaları çalıştır, sonuçları kıyasla \n",
    " \n",
    " Notlar:\n",
    " - ilk 5 sütun correlation a koyulmadı. bunların da koyulması gerekir mi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desicion Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non corelated X'ler için "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5242986961675227\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1804  382]\n",
      " [2026  850]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.47      0.83      0.60      2186\n",
      "        SELL       0.69      0.30      0.41      2876\n",
      "\n",
      "    accuracy                           0.52      5062\n",
      "   macro avg       0.58      0.56      0.51      5062\n",
      "weighted avg       0.60      0.52      0.49      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.30)\n",
    "cart1 = DecisionTreeClassifier()\n",
    "cart_model1 = cart1.fit(X_train1, y_train)\n",
    "y_pred = cart_model1.predict(X_test1)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print('-------------------------------')\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    9.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler : {'max_depth': 50, 'min_samples_split': 200}\n"
     ]
    }
   ],
   "source": [
    "cart_grid1 = {\"max_depth\":[50,100,200,300], \"min_samples_split\":[100,150,200,300]}\n",
    "cart_cv1 = GridSearchCV(cart1, cart_grid1, cv=10, n_jobs =-1, verbose = 2)\n",
    "cart_cv_model1 = cart_cv1.fit(X_train1, y_train)\n",
    "print('En iyi parametreler : ' + str(cart_cv_model1.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.5655867246147768\n",
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1584  602]\n",
      " [1597 1279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.50      0.72      0.59      2186\n",
      "        SELL       0.68      0.44      0.54      2876\n",
      "\n",
      "    accuracy                           0.57      5062\n",
      "   macro avg       0.59      0.58      0.56      5062\n",
      "weighted avg       0.60      0.57      0.56      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cart_1 = DecisionTreeClassifier(max_depth =50 , min_samples_split=200 )\n",
    "cart_tuned1 = cart_1.fit(X_train1, y_train)\n",
    "y_pred = cart_tuned1.predict(X_test1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy : ', accuracy)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest ile bulduğumuz importance X'ler için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1073 1113]\n",
      " [1238 1638]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.46      0.49      0.48      2186\n",
      "        SELL       0.60      0.57      0.58      2876\n",
      "\n",
      "    accuracy                           0.54      5062\n",
      "   macro avg       0.53      0.53      0.53      5062\n",
      "weighted avg       0.54      0.54      0.54      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.30)\n",
    "cart2 = DecisionTreeClassifier()\n",
    "cart_model2 = cart2.fit(X_train2, y_train)\n",
    "y_pred = cart_model2.predict(X_test2)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print('-------------------------------')\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   39.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler : {'max_depth': 100, 'min_samples_split': 300}\n"
     ]
    }
   ],
   "source": [
    "cart_grid2 = {\"max_depth\":[50,100,200,300], \"min_samples_split\":[100,150,200,300]}\n",
    "cart_cv2 = GridSearchCV(cart2, cart_grid2, cv=10, n_jobs =-1, verbose = 2)\n",
    "cart_cv_model2 = cart_cv2.fit(X_train2, y_train)\n",
    "print('En iyi parametreler : ' + str(cart_cv_model2.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1091 1095]\n",
      " [1283 1593]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.46      0.50      0.48      2186\n",
      "        SELL       0.59      0.55      0.57      2876\n",
      "\n",
      "    accuracy                           0.53      5062\n",
      "   macro avg       0.53      0.53      0.53      5062\n",
      "weighted avg       0.54      0.53      0.53      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cart_2 = DecisionTreeClassifier(max_depth = 100, min_samples_split=300)\n",
    "cart_tuned_2 = cart_2.fit(X_train2, y_train)\n",
    "y_pred = cart_tuned_2.predict(X_test2)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1072 1114]\n",
      " [1430 1446]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.43      0.49      0.46      2186\n",
      "        SELL       0.56      0.50      0.53      2876\n",
      "\n",
      "    accuracy                           0.50      5062\n",
      "   macro avg       0.50      0.50      0.49      5062\n",
      "weighted avg       0.51      0.50      0.50      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.30)\n",
    "cart3 = DecisionTreeClassifier()\n",
    "cart_model3 = cart3.fit(X_train3, y_train)\n",
    "y_pred = cart_model3.predict(X_test3)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print('-------------------------------')\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:   36.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler : {'max_depth': 50, 'min_samples_split': 200}\n"
     ]
    }
   ],
   "source": [
    "cart_grid3 = {\"max_depth\":[50,100,200,300], \"min_samples_split\":[100,150,200,300]}\n",
    "cart_cv3 = GridSearchCV(cart3, cart_grid3, cv=10, n_jobs =-1, verbose = 2)\n",
    "cart_cv_model3 = cart_cv3.fit(X_train3, y_train)\n",
    "print('En iyi parametreler : ' + str(cart_cv_model3.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1154 1032]\n",
      " [1534 1342]]\n",
      "-------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.43      0.53      0.47      2186\n",
      "        SELL       0.57      0.47      0.51      2876\n",
      "\n",
      "    accuracy                           0.49      5062\n",
      "   macro avg       0.50      0.50      0.49      5062\n",
      "weighted avg       0.51      0.49      0.49      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cart_3 = DecisionTreeClassifier(max_depth = 50, min_samples_split=200)\n",
    "cart_tuned_3 = cart_3.fit(X_train3, y_train)\n",
    "y_pred = cart_tuned_3.predict(X_test3)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print('-------------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Corelated X'ler ile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1938  248]\n",
      " [2431  445]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.44      0.89      0.59      2186\n",
      "        SELL       0.64      0.15      0.25      2876\n",
      "\n",
      "    accuracy                           0.47      5062\n",
      "   macro avg       0.54      0.52      0.42      5062\n",
      "weighted avg       0.56      0.47      0.40      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train1, X_test1, y_train, y_test = splitting(X1_1, y, 0.30)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model1 = RandomForestClassifier().fit(X_train1, y_train)\n",
    "y_pred = rf_model1.predict(X_test1)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print('-------------------------------')\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 858 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  7.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'max_depth': 7, 'max_features': 2, 'min_samples_split': 150, 'n_estimators': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  9.5min finished\n"
     ]
    }
   ],
   "source": [
    "rf_params1 = {\"max_depth\":[5,7,8,10],\n",
    "             \"min_samples_split\":[100,150,200,300],\n",
    "             \"max_features\": [2,5,8], \n",
    "             \"n_estimators\": [10,500,1000]}\n",
    "rf_model1 = RandomForestClassifier()\n",
    "rf_cv_model1 = GridSearchCV(rf_model1,\n",
    "                            rf_params1,\n",
    "                            cv=10,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=5)\n",
    "rf_cv_model1.fit(X_train1, y_train)\n",
    "print(\"En iyi parametreler: \"+str(rf_cv_model1.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1834  352]\n",
      " [2277  599]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.45      0.84      0.58      2186\n",
      "        SELL       0.63      0.21      0.31      2876\n",
      "\n",
      "    accuracy                           0.48      5062\n",
      "   macro avg       0.54      0.52      0.45      5062\n",
      "weighted avg       0.55      0.48      0.43      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_tuned_1 = RandomForestClassifier(max_depth=7, max_features=2, min_samples_split=150, n_estimators=10)\n",
    "rf_tuned_1.fit(X_train1, y_train)\n",
    "y_pred = rf_tuned_1.predict(X_test1)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print('-------------------------------')\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest ile bulduğumuz importance X'ler için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1892  294]\n",
      " [2441  435]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.44      0.87      0.58      2186\n",
      "        SELL       0.60      0.15      0.24      2876\n",
      "\n",
      "    accuracy                           0.46      5062\n",
      "   macro avg       0.52      0.51      0.41      5062\n",
      "weighted avg       0.53      0.46      0.39      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train, y_test = splitting(X1_2, y, 0.30)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model2 = RandomForestClassifier().fit(X_train2, y_train)\n",
    "y_pred = rf_model2.predict(X_test2)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print('-------------------------------')\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 858 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 17.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'max_depth': 5, 'max_features': 2, 'min_samples_split': 300, 'n_estimators': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 25.0min finished\n"
     ]
    }
   ],
   "source": [
    "rf_params2 = {\"max_depth\":[5,7,8,10],\n",
    "             \"min_samples_split\":[100,150,200,300],\n",
    "             \"max_features\": [2,5,8], \n",
    "             \"n_estimators\": [10,500,1000]}\n",
    "rf_model2 = RandomForestClassifier()\n",
    "rf_cv_model2 = GridSearchCV(rf_model2,\n",
    "                            rf_params2,\n",
    "                            cv=10,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=5)\n",
    "rf_cv_model2.fit(X_train2, y_train)\n",
    "print(\"En iyi parametreler: \"+str(rf_cv_model2.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1388  798]\n",
      " [2016  860]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.41      0.63      0.50      2186\n",
      "        SELL       0.52      0.30      0.38      2876\n",
      "\n",
      "    accuracy                           0.44      5062\n",
      "   macro avg       0.46      0.47      0.44      5062\n",
      "weighted avg       0.47      0.44      0.43      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_tuned_2 = RandomForestClassifier(max_depth=5, max_features=2, min_samples_split=300, n_estimators=10)\n",
    "rf_tuned_2.fit(X_train2, y_train)\n",
    "y_pred = rf_tuned_2.predict(X_test2)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print('-------------------------------')\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[1297  889]\n",
      " [1773 1103]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.42      0.59      0.49      2186\n",
      "        SELL       0.55      0.38      0.45      2876\n",
      "\n",
      "    accuracy                           0.47      5062\n",
      "   macro avg       0.49      0.49      0.47      5062\n",
      "weighted avg       0.50      0.47      0.47      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train3, X_test3, y_train, y_test = splitting(X1_3, y, 0.30)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model3 = RandomForestClassifier().fit(X_train3, y_train)\n",
    "y_pred = rf_model3.predict(X_test3)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print('-------------------------------')\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 858 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 28.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'max_depth': 5, 'max_features': 5, 'min_samples_split': 100, 'n_estimators': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 39.7min finished\n"
     ]
    }
   ],
   "source": [
    "rf_params3 = {\"max_depth\":[5,7,8,10],\n",
    "             \"min_samples_split\":[100,150,200,300],\n",
    "             \"max_features\": [2,5,8], \n",
    "             \"n_estimators\": [10,500,1000]}\n",
    "rf_model3 = RandomForestClassifier()\n",
    "rf_cv_model3 = GridSearchCV(rf_model3,\n",
    "                            rf_params3,\n",
    "                            cv=10,\n",
    "                            n_jobs=-1,\n",
    "                            verbose=5)\n",
    "rf_cv_model3.fit(X_train3, y_train)\n",
    "print(\"En iyi parametreler: \"+str(rf_cv_model3.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Counfusion matrix: \n",
      " [[ 673 1513]\n",
      " [1039 1837]]\n",
      "-------------------------------\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BUY       0.39      0.31      0.35      2186\n",
      "        SELL       0.55      0.64      0.59      2876\n",
      "\n",
      "    accuracy                           0.50      5062\n",
      "   macro avg       0.47      0.47      0.47      5062\n",
      "weighted avg       0.48      0.50      0.48      5062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_tuned_3 = RandomForestClassifier(max_depth=5, max_features=5, min_samples_split=100, n_estimators=10)\n",
    "rf_tuned_3.fit(X_train3, y_train)\n",
    "y_pred = rf_tuned_3.predict(X_test3)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print('-------------------------------')\n",
    "print(\"Counfusion matrix: \\n\",confusion_mat)\n",
    "print('-------------------------------')\n",
    "print('Classification report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
